import streamlit as st
import google.generativeai as genai

# Inicializa o modelo Gemini e armazena-o em st.session_state para persist√™ncia
# Esta √© a parte crucial para o erro que voc√™ est√° a ver.
if "gemini_model" not in st.session_state:
    st.session_state["gemini_model"] = genai.GenerativeModel('gemini-2.0-flash') # Modelo de vis√£o para sugest√µes de vasos

   # --- Configura√ß√£o da P√°gina Streamlit (DEVE SER A PRIMEIRA CHAMADA DO ST) ---
st.set_page_config(page_title="Chatbot de Plantas", page_icon="üåø", layout="centered")

# --- Fun√ß√£o para obter informa√ß√µes e sugest√µes de vasos da Gemini ---
def obter_informacao_planta(nome_planta):
    try:
        # Acessa o modelo a partir de st.session_state
        model = st.session_state["gemini_model"]
        prompt = [
            f"Forne√ßa informa√ß√µes sobre os cuidados da planta chamada '{nome_planta}'. Seja conciso e relevante para um iniciante.",
            "Al√©m disso, sugira 3 tipos de vasos que seriam adequados para essa planta, fornecendo uma breve descri√ß√£o de cada um e incluindo, se poss√≠vel, links para imagens desses vasos. Se n√£o for poss√≠vel um link direto, descreva o vaso de forma que uma busca por imagem seja f√°cil."
        ]
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        return f"Desculpe, ocorreu um erro ao buscar informa√ß√µes sobre '{nome_planta}': {e}"

# --- Interface do Chatbot com Streamlit ---
st.title("üåø Chatbot de Plantas com Gemini")
st.markdown("Pergunte-me sobre cuidados com plantas e sugest√µes de vasos!")

# Inicializa o hist√≥rico de mensagens na sess√£o do Streamlit
if "messages" not in st.session_state:
    st.session_state["messages"] = [{"role": "assistant", "content": "Ol√°! Pergunte-me sobre plantas."}]

# Exibe as mensagens do hist√≥rico
for msg in st.session_state["messages"]:
    st.chat_message(msg["role"]).write(msg["content"])

# Caixa de entrada para o usu√°rio
if prompt := st.chat_input("Digite o nome de uma planta..."):
    # Adiciona a mensagem do usu√°rio ao hist√≥rico e exibe
    st.session_state["messages"].append({"role": "user", "content": prompt})
    st.chat_message("user").write(prompt)

    # Obt√©m a resposta do Gemini
    with st.spinner("Buscando informa√ß√µes..."): # Mostra um indicador de carregamento
        resposta_gemini = obter_informacao_planta(prompt)

    st.session_state["messages"].append({"role": "assistant", "content": resposta_gemini})
    st.chat_message("assistant").write(resposta_gemini)

